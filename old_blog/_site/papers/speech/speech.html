<!doctype html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>Aaron's Wiki by </title>

    <link rel="stylesheet" href="/assets/css/style.css?v=">
    <meta name="viewport" content="width=device-width">
    <script src='//cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js'></script>
    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
  </head>
  <body>
    <div class="wrapper">
      <header>
        <h1>Aaron's Wiki</h1>
        <!-- <p>Hello, thanks for visiting my personal wiki.</p> -->
        <!-- <h2>Projects</h2> -->
        <p class="view"><a href="blog/index">main page</a></p>
        <p class="view"><a href="blog/projects/projects_sum.html">Projects</a></p>
        <p class="view"><a href="blog/papers/papers_index.html">Paper Reviews</a></p>
        <p class="view"><a href="blog/books/books_index.html">Book Reviews</a></p>
        <p class="view"><a href="blog/coding/coding_index.html">Coding and APIs</a></p>
        <p class="view"><a href="blog/posts/posts_index.html">Posts</a></p>
        <!-- <p class="view"><a href="/index">main page</a></p>
        <p class="view"><a href="/projects/projects_sum.html">Projects</a></p>
        <p class="view"><a href="/papers/papers_index.html">Paper Reviews</a></p>
        <p class="view"><a href="/books/books_index.html">Book Reviews</a></p>
        <p class="view"><a href="/coding/coding_index.html">Coding and APIs</a></p>
        <p class="view"><a href="/posts/posts_index.html">Posts</a></p> -->
        <!-- <p class="view"><a href="/blog/papers/nn_models/model_summary.html">Papers</a></p> -->
        <!-- <h2>Book and Code Reviews</h2> -->
        <!-- <p class="view"><a href="">Books</a></p>
        <p class="view"><a href="">Python</a></p>
        <p class="view"><a href="">C++</a></p> -->
        <!-- <h2>Contacts</h2> -->
        

        

        
      </header>
      <section>

      <h1 id="-list-of-papers"><a href="#list"></a> List of papers</h1>
<ul>
  <li>Conditional Computations <a href="#inference">details</a></li>
</ul>

<p>Various forms of conditional computation have been proposed as a way to increase model capacity without a proportional increase in computational costs.
  In these schemes, large parts of a network are active or inactive on a per-example basis.
    1. Outrageously large neural networks:
the sparsely-gated mixture-of-experts layer
    2. Language Modeling with Gated Convolutional Networks
    3. Multi-mention Learning for Reading Comprehension with Neural Cascades</p>
<hr />

<h2 id="-conditional-computations"><a id="train"></a> Conditional Computations</h2>
<h4 id="1-outrageously-large-neural-networks-the-sparsely-gated-mixture-of-experts-layer">1. Outrageously large neural networks: the sparsely-gated mixture-of-experts layer</h4>
<p><strong>Review</strong>(<a href="http://jaewoong.org/pubs/fpga17-next-generation-dnns.pdf">Paper link</a>)</p>

<p>The MoE consists of a number of experts, each a simple feed-forward neural network, and a trainable gating network which selects a sparse combination of the experts to process each input.
The authors have observed that the gating network tends to converge to a state where it always produces large weights for the same few experts. This imbalance is self-reinforcing, as the favored experts are trained more rapidly and thus are selected even more by the gating network.
Defining a soft constraint (another loss term into the cost function) can help avoiding this local minimum.</p>

<h4 id="2-language-modeling-with-gated-convolutional-networks">2. Language Modeling with Gated Convolutional Networks</h4>
<p><!-- **Review**([Paper link]()) -->
 I did not fully understand the paper, a later review after reading on LSTMs is required.
 The paper proposed a new gating mechanism.
 The authors claim their gated linear units reduce the vanishing gradient problem for deep architectures by providing a linear path for the gradients while retaining non-linear capabilities</p>

<h4 id="3-multi-mention-learning-for-reading-comprehension-with-neural-cascades">3. Multi-mention Learning for Reading Comprehension with Neural Cascades</h4>
<p><strong>Review</strong>(<a href="https://arxiv.org/abs/1711.00894">Paper link</a>)
Reading comprehension is a task of answering questions based on a set of
documents. Long short-term memory networks (LSTM)</p>


      </section>
      <footer>
        
        <p><small>Hosted on GitHub Pages &mdash; Theme by <a href="https://github.com/orderedlist">orderedlist</a></small></p>
      </footer>
    </div>
    <script src="/assets/js/scale.fix.js"></script>


  
  </body>
</html>
