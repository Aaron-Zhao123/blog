---
layout: default
---

# [](#nn)Neural Networks
### [Models](/blog/papers/nn_models/model_summary.html)

A collection of popular neural network models: from the old LeNet model to ResNet model.
Some interesting network architectures are also collected.

### [Compression](/blog/papers/pruning/pruning_summary.html)
A range of compression techniques are summarized:
* Pruning
* Quantization
* Regularization
* Varying network structure

Pruning refers to move away connections in a neural network for compressing the size of it, both fine-grained and coarse-grained
pruning are discussed.
Vairous quantization methods: fixed-point, dynamic fixed-point, binarized, tenary.
Novel regularizers are considered as compression techniques.

### [ Training](/blog/papers/train/train_summary.html)
Interesting benchmarks and methods of training neural networks

# [Reinforcement learning](/blog/papers/nn_app/app_summary.html)
How to apply neural networks in other domains.
A collection of Reinforcement learning techniques, although this is not my field.

# [Neural Network Accelerators](/blog/papers/nn_accelerator/acc_summary.html)
* Inference Accelerators -> aiming at low-power consumption
* Training Accelerators
* Frameworks
Accelerators for low-power systems, and accelerators in the cloud.

# [](#fpga)FPGAs
### [Applications](/blog/papers/fpga_nn/fpgann_summary.html)
My main focus on FPGAs in applications are still related to hardware architectures. This section specifically focus on the publications FPGA-based implementation of neural network accelerators in the following conferences: FPGA, FCCM, FPL and FPT.

### [Cloud](/blog/papers/fpga_cloud/fpgncloud_summary.html)
The interest of FPGAs in the cloud origins from the Catapult project from Microsoft.

### [High level synthesis](/blog/papers/pruning/pruning_summary.html)
I have a particular interest in HLS. The popular HLS tools include the followings: Vivado HLS, Altera OpenCL and Legup.

# [](#others)Networking
## [Scheduling Algorithms](/blog/papers/others/scheduling.html)
My research internship in Microsoft puts a focus on input-buffered switches in datacenters
