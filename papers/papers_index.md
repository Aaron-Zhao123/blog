---
layout: default
---

# [](#nn)Neural Networks
### [Models](/blog/papers/nn_models/model_summary.html)

A collection of popular neural network models: from the old LeNet model to ResNet model.
Some interesting network architectures are also collected.

### [Compression](/blog/papers/compression/compression.html)


### [ Training and Novel Networks](/blog/papers/train/train_summary.html)
Interesting benchmarks and methods of training neural networks.

### [ Speech models](/blog/papers/speech/speech.html)
Mainly focus on keeping in track with state-of-the-art NLP models.

### [Neural Network Accelerators](/blog/papers/nn_accelerator/acc_summary.html)
* Inference Accelerators -> aiming at low-power consumption
* Training Accelerators
* Frameworks
Accelerators for low-power systems, and accelerators in the cloud.

### [Reinforcement learning](/blog/papers/nn_app/app_summary.html)
How to apply neural networks in other domains.
A collection of Reinforcement learning techniques, although this is not my field.

***

# [](#fpga)FPGAs
### [Applications](/blog/papers/fpga/fpga_nn.html)
My main focus on FPGAs in applications are still related to hardware architectures. This section specifically focus on the publications FPGA-based implementation of neural network accelerators in the following conferences: FPGA, FCCM, FPL and FPT.

### [Cloud](/blog/papers/fpga/fpga_cloud.html)
The interest of FPGAs in the cloud origins from the Catapult project from Microsoft.

### [High level synthesis](/blog/papers/fpga/fpga_hls.html)
HLS boosts working efficiency on FPGAs. The popular HLS tools include the followings: Vivado HLS, Altera OpenCL and Legup.

***

# [](#networking)Networking
### [Scheduling Algorithms](/blog/papers/others/scheduling.html)
My research internship in Microsoft puts a focus on input-buffered switches in data centers

***

# [](#others)Papers to read
I keep a collection of the papers that I plan to read
